{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43090547-5a5c-406a-9008-dea45f41618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd37fbee-5ad5-44fb-a84b-50c403afcb72",
   "metadata": {},
   "source": [
    "\n",
    "The Probability Mass Function (PMF) and Probability Density Function (PDF) are fundamental concepts in probability and statistics, used to describe the probability distribution of a discrete random variable (PMF) and a continuous random variable (PDF), respectively.\n",
    "\n",
    "Probability Mass Function (PMF):\n",
    "\n",
    "A Probability Mass Function (PMF) is a function that describes the probability of each possible outcome of a discrete random variable. It maps each value of the random variable to its probability of occurrence. In a PMF, the probabilities associated with each outcome sum up to 1.\n",
    "\n",
    "PMFs are typically used for discrete random variables, where the possible outcomes are countable and distinct. Examples of discrete random variables include the number of heads in multiple coin flips, the number of defects in a batch of products, or the outcome of rolling a fair six-sided die.\n",
    "\n",
    "For example, let's consider a fair six-sided die. The PMF for this die is as follows:\n",
    "\n",
    "P(X = 1) = 1/6\n",
    "P(X = 2) = 1/6\n",
    "P(X = 3) = 1/6\n",
    "P(X = 4) = 1/6\n",
    "P(X = 5) = 1/6\n",
    "P(X = 6) = 1/6\n",
    "In this case, the PMF describes the probabilities of obtaining each of the six possible outcomes when rolling the die.\n",
    "\n",
    "Probability Density Function (PDF):\n",
    "\n",
    "A Probability Density Function (PDF) is a function that describes the probability distribution of a continuous random variable. Unlike discrete random variables, continuous random variables can take on an infinite number of possible values within a range. The PDF doesn't provide the probability of specific values but rather gives the probability density at each point in the range. The total area under the PDF curve over a specific interval represents the probability of the variable falling within that interval.\n",
    "\n",
    "PDFs are commonly used for continuous random variables, such as the height of individuals in a population, the time it takes for a process to complete, or the measurement of a chemical concentration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a24f70c6-67ba-4db0-8fcc-c4c1d84a2e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1880807d-4a7f-41c2-9690-5cb742859b21",
   "metadata": {},
   "source": [
    "\n",
    "The Cumulative Distribution Function (CDF) is a fundamental concept in probability and statistics. It describes the probability that a random variable takes on a value less than or equal to a specific value. In essence, the CDF provides a cumulative view of the probability distribution of a random variable.\n",
    "\n",
    "F(x)=P(X≤x)\n",
    "F(x) is the CDF of the random variable X at the value x\n",
    "P(X≤x) represents the probability that X is less than or equal to x.\n",
    "\n",
    "Let's consider a simple example using a fair six-sided die. The CDF for this die is as follows:\n",
    "F(1)=P(X≤1)=1/6\n",
    "F(2)=P(X≤2)=2/6=1/3\n",
    "F(3)=P(X≤3)=3/6=1/2\n",
    "F(4)=P(X≤4)=4/6=2/3\n",
    "F(5)=P(X≤5)=5/6\n",
    "F(6)=P(X≤6)=6/6=1\n",
    "\n",
    "\n",
    "In this example, for each value of x, the CDF provides the probability that the outcome of rolling the diceis less than or equal to x .\n",
    "for instance F(3) = probability of rolling a 1,2 or 3 on the dice, which is 1/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8926c02-0958-4567-8f38-6664c14cd943",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0f6220-a863-4b48-9822-8b91ee80f855",
   "metadata": {},
   "source": [
    "it is one of the most widely used probability distributions in statistics and has numerous applications in various fields. Some examples of situations where the normal distribution might be used as a model include:\n",
    "1. Height of individual\n",
    "2. weight of objects\n",
    "3. test score\n",
    "\n",
    "The parameters of the normal distribution are the mean (μ) and the standard deviation (σ). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f836068-6639-4f8a-8fad-fe5de2e94002",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2cb81f-da2a-4129-92a4-5a26ef2d162d",
   "metadata": {},
   "source": [
    "1. Commonality in Natural Phenomena: The Normal Distribution frequently arises in nature and real-world phenomena. Many naturally occurring processes and measurements tend to follow this distribution. Therefore, understanding the normal distribution is essential for analyzing and modeling various aspects of the world.\n",
    "\n",
    "2. Central Limit Theorem: The Central Limit Theorem states that the sampling distribution of the sample mean of a random sample, drawn from any population, will be approximately normally distributed if the sample size is sufficiently large. This theorem underpins many statistical methods, making the normal distribution a foundation for statistical inference.\n",
    "\n",
    "3. Statistical Inference: Normal distribution assumptions are at the core of many statistical techniques, such as hypothesis testing, confidence intervals, and regression analysis. Knowing how to work with normal distributions is crucial for conducting statistical analyses accurately.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ef2d59d6-a00b-45ce-9887-99fc8d1dcaf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62cccfd9-a625-488e-ae9b-bed57bc63ef6",
   "metadata": {},
   "source": [
    "Bernauli Distribution:- it is a discrete probability distribution of a random variable whcih takes value 1 with probability p and 0 with probability 1-p.\n",
    "\n",
    "eg:- tossing a coin\n",
    "p(H)=0.5\n",
    "p(T) = 1-0.5 = 0.5\n",
    "    \n",
    "Binomial distribution:- in this distribution with parameters n&p is the discrete probability distribution of the no. of sucess in a seq of n independednt experiments , each asking a Yes or No question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34579085-2488-496c-831b-95aba9908168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c11756c-0c4f-4eab-9612-7f05ae6ff3aa",
   "metadata": {},
   "source": [
    "Mean= 50\n",
    "std=10\n",
    "\n",
    "it will be one tail test, we will be using Z test\n",
    "\n",
    "=(60-50)/10 = 1\n",
    "area under the curve using Z - Tabe is = .84134\n",
    "\n",
    "so probability will be 84% that point will be greater than 60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d1c82a6-cd0f-4c61-a83f-991626f64e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d158b4-f725-481e-b44a-d0621a2c772c",
   "metadata": {},
   "source": [
    "A uniform distribution is a probability distribution in statistics where all values within a given range are equally likely to occur. In other words, each possible outcome has an equal probability of happening, and the probability density function (PDF) is constant over the entire range. It's often represented graphically as a flat, horizontal line.\n",
    "\n",
    "Key characteristics of a uniform distribution:\n",
    "\n",
    "Equal Probability: Every value within the specified range has the same probability of occurring.\n",
    "\n",
    "Constant PDF: The probability density function remains constant within the range and is zero outside of it.\n",
    "\n",
    "Defined Range: A uniform distribution is typically defined over a specific interval or range, denoted as [a, b], where \"a\" is the lower bound and \"b\" is the upper bound.\n",
    "\n",
    "Probability Density: The probability density within the range is such that the area under the probability density curve is equal to 1, indicating that the total probability within the range is 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0fc8aa8-af43-4548-96d2-fb6d81645b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13acf038-9243-493f-b8c3-6f7215153086",
   "metadata": {},
   "source": [
    "The z-score, also known as the standard score or standardized score, is a measure of how many standard deviations a particular data point is away from the mean (average) of a dataset. It's a fundamental concept in statistics and is used to standardize data and make it easier to compare and analyze values from different distributions.\n",
    "\n",
    "Standardization: One of the primary uses of z-scores is to standardize data. By converting data points into z-scores, you transform the values into a common scale with a mean of 0 and a standard deviation of 1. This makes it easier to compare and analyze data from different datasets.\n",
    "\n",
    "Interpretation: A positive z-score indicates that a data point is above the mean, while a negative z-score indicates that it is below the mean. The magnitude of the z-score indicates how far the data point is from the mean in terms of standard deviations.\n",
    "\n",
    "Comparison: Z-scores allow you to compare data points from different datasets with different units and scales. For example, you can compare the performance of students on different exams or the heights of individuals from different populations.\n",
    "\n",
    "Probability and Normal Distribution: In statistics, z-scores are often used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf9d822f-ef10-4ed7-8158-57256342345e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4f829e-38e2-4487-8f4a-e47d05373ba4",
   "metadata": {},
   "source": [
    "Central Limit Theorem: Regardless of the shape of the population distribution, the sampling distribution of the sample mean (or sum) will tend to be approximately normally distributed if the sample size is large enough. Moreover, the mean of the sampling distribution will be equal to the population mean, and the standard deviation of the sampling distribution (standard error) will be equal to the population standard deviation divided by the square root of the sample size.\n",
    "\n",
    "Approximation to Normal Distribution: The CLT is crucial because it allows us to make inferences about a population even when we do not know its underlying distribution. It tells us that if we take sufficiently large random samples from any population, the distribution of the sample means will resemble a normal distribution, regardless of the shape of the original population distribution.\n",
    "\n",
    "Large Sample Size: The CLT emphasizes the importance of having a large sample size to ensure that the sampling distribution of the sample mean closely approximates a normal distribution. As a rule of thumb, a sample size of 30 or more is often considered sufficiently large for the CLT to apply, but the larger the sample size, the better the approximation.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6833dc7f-4a27-4a05-a5ad-313fbb93c77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6425693-a3d4-4bdc-8c1e-98e73fe8e61e",
   "metadata": {},
   "source": [
    "Random Sampling: The samples must be drawn randomly from the population of interest. This means that every member of the population has an equal chance of being selected for the sample. Non-random or biased sampling can violate the assumptions of the CLT.\n",
    "\n",
    "Independence: The individual observations within each sample must be independent of each other. In other words, the value of one observation should not depend on or be influenced by the values of other observations in the same sample. Independence is crucial for the CLT to apply.\n",
    "\n",
    "Sample Size: While the CLT can provide reasonable approximations with various sample sizes, it is most accurate and robust when the sample size is sufficiently large. As a general rule of thumb, a sample size of 30 or more is often considered large enough for the CLT to apply. Smaller sample sizes may also work if the population is not highly skewed or has extreme outliers, but larger samples are generally preferred."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6124141-0e60-45c8-b826-eb4cb20cb91e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
