{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "82523f04-7520-4103-9b13-770e9ef6dc81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. What is the KNN algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad821dca-5dcf-4f7a-9b66-51c4e2be8a7b",
   "metadata": {},
   "source": [
    "The k-Nearest Neighbors (KNN) algorithm is a simple, yet powerful machine learning technique used for both classification and regression. It's part of a broader family of instance-based learning or non-parametric learning algorithms, where the function is approximated locally and all computation is deferred until function evaluation.\n",
    "\n",
    "Here’s a breakdown of how KNN works:\n",
    "\n",
    "1. **Basic Concept**: KNN operates on the simple principle of identifying the 'k' nearest data points to a query point (the point you want to make a prediction for), based on some distance metric (commonly Euclidean distance), and making predictions based on these 'k' neighbors.\n",
    "\n",
    "2. **For Classification**: In a classification context, KNN assigns a class to the query point based on the majority class among its 'k' nearest neighbors. For instance, if 'k' is 5, and 3 out of 5 neighbors are of Class A and 2 are of Class B, the algorithm would classify the query point as Class A.\n",
    "\n",
    "3. **For Regression**: In regression tasks, KNN predicts the value for the query point based on the average (or sometimes median) of the values of its 'k' nearest neighbors.\n",
    "\n",
    "4. **Distance Metrics**: The choice of distance metric can vary based on the type of data. Euclidean distance is the most common, but others like Manhattan distance, Minkowski distance, or Hamming distance for categorical variables, can be used.\n",
    "\n",
    "5. **Choosing 'k'**: The choice of 'k' (the number of neighbors) is crucial. A smaller 'k' makes the model sensitive to noise, whereas a larger 'k' makes it computationally expensive and may include points that are significantly different from the query point. Cross-validation is often used to find an optimal 'k'.\n",
    "\n",
    "6. **Features and Scaling**: KNN is sensitive to the scale of the data, so feature scaling (like normalization or standardization) is important for it to work correctly. It's also sensitive to irrelevant or redundant features, as they can lead to inaccurate distance calculations.\n",
    "\n",
    "7. **Advantages**: KNN is easy to understand and implement, works well with a small number of input variables (features), and is versatile for both classification and regression.\n",
    "\n",
    "8. **Disadvantages**: It becomes significantly slower as the size of the data increases, making it not ideal for large datasets. It also struggles with high-dimensional data (the curse of dimensionality) and is sensitive to imbalanced data.\n",
    "\n",
    "KNN's simplicity and effectiveness in certain scenarios make it a popular choice for tackling basic machine learning problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e44bbdfb-9b0d-419a-9863-cd12d244c0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. How do you choose the value of K in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fbe671-e967-4b47-9740-e518849f4114",
   "metadata": {},
   "source": [
    "Choosing the right value of 'k' in the k-Nearest Neighbors (KNN) algorithm is crucial as it directly influences the performance of the model. There is no definitive rule for choosing 'k,' but various methods and considerations can guide you to select an appropriate value:\n",
    "\n",
    "1. **Square Root Rule**: A common heuristic is to choose 'k' as the square root of the number of data points in the training set. This is just a starting point and may not always lead to the best performance.\n",
    "\n",
    "2. **Cross-Validation**: The most reliable method is to use cross-validation:\n",
    "   - Split your dataset into a training set and a validation set (or use k-fold cross-validation).\n",
    "   - Train the KNN algorithm for different values of 'k'.\n",
    "   - Evaluate the performance of each model on the validation set.\n",
    "   - Choose the value of 'k' that gives the best performance on the validation set.\n",
    "\n",
    "3. **Bias-Variance Tradeoff**:\n",
    "   - A smaller 'k' leads to a model with low bias and high variance. In such cases, the model captures the noise in the training data, leading to overfitting.\n",
    "   - A larger 'k' leads to a model with high bias and low variance. This may result in underfitting, where the model is overly simplistic.\n",
    "\n",
    "4. **Avoiding Odd/Even 'k' in Binary Classification**: In binary classification, it's generally advisable to avoid using an even number for 'k' to prevent ties, i.e., having an equal number of nearest neighbors from each class.\n",
    "\n",
    "5. **Problem Specifics**: Sometimes the choice of 'k' can be influenced by the specifics of the dataset and problem. For example, in imbalanced datasets, a larger 'k' might be necessary to avoid bias toward the majority class.\n",
    "\n",
    "6. **Distance Metric**: The choice of distance metric can influence the optimal 'k'. If you change the distance metric, it's a good idea to reevaluate the best 'k'.\n",
    "\n",
    "7. **Computational Resources**: Larger values of 'k' require more computation for each prediction. If you're working with very large datasets and/or limited computational resources, this might influence your choice.\n",
    "\n",
    "8. **Rule of Thumb**: As a general rule of thumb, try several values of 'k' and compare the results. Values like 3, 5, 7, and 10 are commonly tried out in initial experiments.\n",
    "\n",
    "9. **Domain Knowledge**: Sometimes, domain-specific knowledge can guide the choice of 'k'. For instance, in a certain application, there might be a reason to believe that a data point should be influenced only by its nearest few or many neighbors.\n",
    "\n",
    "Remember, there is no one-size-fits-all approach, and often the choice of 'k' is more of an art than a science, requiring experimentation and validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dff9d87e-f157-4a82-a2a0-bb94a3668f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. What is the difference between KNN classifier and KNN regressor?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f825be7b-e0bb-4352-9126-0ba16fded932",
   "metadata": {},
   "source": [
    "The k-Nearest Neighbors (KNN) algorithm can be used for both classification and regression, and the core idea of finding the 'k' nearest neighbors based on a distance metric remains the same in both. However, the way KNN makes predictions differs between the two:\n",
    "\n",
    "1. **KNN Classifier**:\n",
    "   - **Purpose**: Used for classification tasks, where the goal is to predict a discrete class label for an observation.\n",
    "   - **How it Works**: After identifying the 'k' nearest neighbors to a query point, the KNN classifier assigns the class to the query point based on a majority vote among its neighbors. That is, the most common class label among the 'k' nearest neighbors is assigned to the query point.\n",
    "   - **Tie-Breaking**: In case of a tie (where two or more classes have the same number of nearest neighbors), the tie can be broken randomly, by weighting the votes based on distance, or by choosing the class of the nearest neighbor among the tied groups.\n",
    "   - **Example Use Case**: Determining whether an email is spam or not, based on the characteristics of emails whose classifications are already known.\n",
    "\n",
    "2. **KNN Regressor**:\n",
    "   - **Purpose**: Used for regression tasks, where the goal is to predict a continuous value.\n",
    "   - **How it Works**: The KNN regressor predicts the value for a query point based on the average (or sometimes the weighted average if distance weighting is used) of the values of its 'k' nearest neighbors. \n",
    "   - **Output**: Instead of a class label, the output is a numerical value that represents the predicted value for the query point, derived from the neighboring points.\n",
    "   - **Example Use Case**: Predicting the price of a house based on the prices of nearby houses with similar features.\n",
    "\n",
    "**Key Differences**:\n",
    "- **Output Type**: Classifier outputs a class label, while Regressor outputs a continuous value.\n",
    "- **Method of Prediction**: Classifier uses a majority voting system among neighbors, whereas Regressor uses averaging or weighted averaging of neighbor values.\n",
    "- **Use Cases**: Classifier is for categorical outcomes, while Regressor is for predicting numerical values.\n",
    "\n",
    "Both share the common KNN framework of relying on proximity in the feature space to make predictions, but they apply this principle to different types of prediction tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "997366c8-dece-4dd9-aa8a-92f28951630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. How do you measure the performance of KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27f6bf9-a6dd-4bb8-b84e-228ac5b84078",
   "metadata": {},
   "source": [
    "Measuring the performance of the k-Nearest Neighbors (KNN) algorithm, like any machine learning model, depends on whether you are using it for a classification or a regression task. Here are the common methods for each:\n",
    "\n",
    "### For KNN Classifier\n",
    "\n",
    "1. **Accuracy**: The most straightforward metric, it measures the proportion of correct predictions out of all predictions made. It’s a good measure when the classes are balanced but can be misleading when class distribution is imbalanced.\n",
    "\n",
    "2. **Precision and Recall**:\n",
    "   - **Precision**: The proportion of true positive predictions in the total predicted positives. It's a measure of the accuracy of the positive predictions.\n",
    "   - **Recall (Sensitivity)**: The proportion of actual positives that were correctly identified. It's important when the cost of false negatives is high.\n",
    "\n",
    "3. **F1 Score**: The harmonic mean of precision and recall. It's useful when you need a balance between precision and recall and there's an uneven class distribution.\n",
    "\n",
    "4. **Confusion Matrix**: A table used to describe the performance of a classification model. It outlines the true positives, false positives, true negatives, and false negatives, providing a clear picture of classification accuracy.\n",
    "\n",
    "5. **ROC-AUC Score**:\n",
    "   - **ROC Curve**: Plots the true positive rate against the false positive rate at various threshold settings.\n",
    "   - **AUC (Area Under the Curve)**: Summarizes the ROC curve into a single value, with higher values indicating better classification performance.\n",
    "\n",
    "6. **K-Fold Cross-Validation**: This technique involves dividing the dataset into k subsets, training the model on k-1 subsets, and testing it on the remaining subset. This is repeated k times, and the average performance across all k trials is calculated.\n",
    "\n",
    "### For KNN Regressor\n",
    "\n",
    "1. **Mean Absolute Error (MAE)**: The average of the absolute differences between the predicted values and the actual values. It gives an idea of how wrong the predictions were.\n",
    "\n",
    "2. **Mean Squared Error (MSE)**: The average of the squared differences between the predicted values and the actual values. It penalizes larger errors more than MAE.\n",
    "\n",
    "3. **Root Mean Squared Error (RMSE)**: The square root of MSE. It's in the same units as the response variable and often more interpretable.\n",
    "\n",
    "4. **R-squared (Coefficient of Determination)**: Indicates the proportion of the variance in the dependent variable that is predictable from the independent variables. It provides a measure of how well observed outcomes are replicated by the model.\n",
    "\n",
    "5. **K-Fold Cross-Validation**: Similar to its use in classification, it’s valuable for assessing the performance of regression models.\n",
    "\n",
    "### General Considerations\n",
    "\n",
    "- **Choosing the Right Metric**: The choice of metric should align with the business objective or the specific problem you're trying to solve.\n",
    "- **Data Imbalance**: In classification, be cautious with metrics like accuracy when dealing with imbalanced datasets.\n",
    "- **Validation Strategy**: Ensure that the model is neither overfitting nor underfitting. Techniques like cross-validation help in validating model performance effectively.\n",
    "\n",
    "Remember, no single metric can capture the full picture of a model's performance, and it's often beneficial to look at multiple metrics to gain a comprehensive understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2c8016f8-170a-4038-9085-28856ee3e304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. What is the curse of dimensionality in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6fc765-d12a-438f-b49a-abb71258e7a1",
   "metadata": {},
   "source": [
    "The \"curse of dimensionality\" in the context of k-Nearest Neighbors (KNN) refers to various issues that arise when analyzing and organizing data in high-dimensional spaces (i.e., spaces with a large number of features). This phenomenon significantly impacts the performance and effectiveness of the KNN algorithm, among others. Here’s how it affects KNN:\n",
    "\n",
    "1. **Distance Metric Becomes Less Informative**: In high-dimensional spaces, the concept of \"nearest neighbors\" becomes less meaningful. The distance between pairs of points converges to a constant value as dimensions increase, making it hard to distinguish close neighbors from distant ones. This is because the volume of the space increases exponentially with each additional dimension, causing the data to become sparse.\n",
    "\n",
    "2. **Overfitting**: With a large number of dimensions, the model starts to fit not just the underlying pattern in the data but also the noise. This is because in high-dimensional spaces, each data point is likely to be an “outlier” in some dimension, leading to overfitting and poor generalization to new samples.\n",
    "\n",
    "3. **Feature Relevance**: Not all features are equally relevant or informative for making predictions. However, KNN treats all features with equal importance, which can degrade the performance when irrelevant or redundant features are present.\n",
    "\n",
    "4. **Computational Complexity**: The computational burden increases with the number of dimensions. For each query, distances need to be computed in this high-dimensional space, which can be computationally expensive and time-consuming.\n",
    "\n",
    "5. **Data Availability**: High-dimensional data often requires an exponentially larger amount of data to maintain the same level of model performance. This phenomenon is sometimes referred to as the “sample size curse of dimensionality.”\n",
    "\n",
    "### Mitigating the Curse of Dimensionality\n",
    "\n",
    "To mitigate the effects of the curse of dimensionality in KNN:\n",
    "\n",
    "1. **Dimensionality Reduction**: Techniques like Principal Component Analysis (PCA), t-Distributed Stochastic Neighbor Embedding (t-SNE), or Linear Discriminant Analysis (LDA) can be used to reduce the number of dimensions while retaining most of the meaningful variance in the data.\n",
    "\n",
    "2. **Feature Selection**: Identify and keep only the most relevant features for the task. This can be done using methods like forward selection, backward elimination, or using models that incorporate feature selection (like Lasso regression).\n",
    "\n",
    "3. **Feature Engineering**: Transforming or combining features in ways that make them more informative and less redundant can also help.\n",
    "\n",
    "4. **Increasing Sample Size**: If feasible, increasing the number of training samples can mitigate some of the issues of high dimensionality.\n",
    "\n",
    "5. **Using Distance Weighting**: Weighting the contribution of neighbors so that nearer neighbors contribute more to the prediction than farther ones.\n",
    "\n",
    "6. **Regularization Techniques**: Applying regularization methods can help to prevent overfitting in high-dimensional spaces.\n",
    "\n",
    "It’s important to balance the model's complexity with the available data and the problem's inherent dimensionality to effectively utilize KNN or any other distance-based algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6afb08b6-c045-4c59-9b9b-d6383be404bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. How do you handle missing values in KNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92fce245-88c3-4460-a648-11be8270a5b1",
   "metadata": {},
   "source": [
    "Handling missing values in data is a critical step before applying the k-Nearest Neighbors (KNN) algorithm, as KNN typically requires complete data for calculating distances between points. Here are some common strategies for dealing with missing values in the context of KNN:\n",
    "\n",
    "1. **Remove Rows with Missing Values**: \n",
    "   - This is the simplest approach where you remove any row in the dataset that contains a missing value. \n",
    "   - It's only practical when the amount of missing data is minimal and does not significantly reduce the sample size.\n",
    "\n",
    "2. **Impute Missing Values**:\n",
    "   - **Mean/Median/Mode Imputation**: Replace missing values with the mean (for continuous variables) or the median/mode (for categorical or skewed continuous variables) of the respective feature. This method is simple but can introduce bias.\n",
    "   - **KNN Imputation**: Use KNN to fill in missing values. The missing value of a point is imputed using the mean value of the 'k' nearest neighbors found in the training set. This method considers the similarity between instances.\n",
    "   - **Model-Based Imputation**: Use regression models, decision trees, or other predictive models to estimate and impute missing values.\n",
    "\n",
    "3. **Weighted KNN**:\n",
    "   - Modify the KNN algorithm to give less weight to a dimension with a missing value when calculating distances. This approach directly incorporates missing data handling into the KNN computation.\n",
    "\n",
    "4. **Use Algorithms that Support Missing Values**:\n",
    "   - If handling missing data is particularly challenging, consider using machine learning algorithms that inherently support missing values, like decision trees or random forests.\n",
    "\n",
    "5. **Data Imputation as a Separate Model**:\n",
    "   - Build a separate predictive model (like a regression model) for each feature with missing values, using other features to predict the missing ones.\n",
    "\n",
    "6. **Avoid Using Features with Too Many Missing Values**:\n",
    "   - If a feature has a significant proportion of missing data, it might be more reasonable to exclude it from the analysis altogether.\n",
    "\n",
    "7. **Flag Missing Values**:\n",
    "   - Create a new binary feature indicating whether data was missing for a particular observation. This can sometimes help the model learn patterns associated with the absence of information.\n",
    "\n",
    "8. **Using Domain Knowledge**:\n",
    "   - Sometimes, domain knowledge can guide the imputation. For instance, if the missing value represents something meaningful (like the absence of a condition), it can be filled in a way that reflects this understanding.\n",
    "\n",
    "It's important to consider the nature of the data, the pattern of missingness (random or systematic), and the proportion of missing data when choosing a strategy. Often, trying multiple approaches and comparing their impacts on model performance is a good practice. Additionally, after imputing missing values, it's essential to check the distribution of the features to ensure that the imputation hasn't significantly distorted the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e0c425d-fb30-4b20-bc9e-ca4185e3f57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. Compare and contrast the performance of the KNN classifier and regressor. Which one is better for\n",
    "# which type of problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e698d319-d839-4a0c-95d4-9b720074ffff",
   "metadata": {},
   "source": [
    "Comparing and contrasting the performance of KNN classifiers and regressors involves understanding the nature of the problem at hand (classification vs. regression), the characteristics of the dataset, and how the KNN algorithm behaves in these different contexts.\n",
    "\n",
    "### KNN Classifier\n",
    "- **Used For**: Categorical target variables where the goal is to assign a discrete label (e.g., spam vs. non-spam).\n",
    "- **Performance Metrics**: Accuracy, Precision, Recall, F1 Score, ROC-AUC, etc.\n",
    "- **Strengths**:\n",
    "  - Simple and easy to understand.\n",
    "  - Effective in cases where the decision boundary is irregular.\n",
    "  - No assumptions about the distributions of classes.\n",
    "- **Weaknesses**:\n",
    "  - Not efficient on imbalanced datasets.\n",
    "  - Suffers in high-dimensional spaces (curse of dimensionality).\n",
    "  - Sensitive to noisy data and irrelevant features.\n",
    "  - Computationally expensive, as it involves calculating distances for each instance during prediction.\n",
    "\n",
    "### KNN Regressor\n",
    "- **Used For**: Continuous target variables where the goal is to predict a numerical value (e.g., house prices).\n",
    "- **Performance Metrics**: Mean Absolute Error (MAE), Mean Squared Error (MSE), Root Mean Squared Error (RMSE), R-squared, etc.\n",
    "- **Strengths**:\n",
    "  - Simple and intuitive.\n",
    "  - Can model non-linear relationships effectively.\n",
    "  - No assumptions about the underlying data distribution.\n",
    "- **Weaknesses**:\n",
    "  - Impacted negatively by the curse of dimensionality.\n",
    "  - Sensitive to outliers since averaging can be affected by extreme values.\n",
    "  - Requires feature scaling for optimal performance.\n",
    "  - Computationally intensive with large datasets.\n",
    "\n",
    "### Which One to Choose?\n",
    "- **Nature of the Output Variable**: \n",
    "  - Use KNN classifier for categorical output variables.\n",
    "  - Use KNN regressor for continuous output variables.\n",
    "- **Data Characteristics**:\n",
    "  - If the dataset has many dimensions, KNN might not be the best choice unless dimensionality reduction is performed.\n",
    "  - For datasets with a lot of noise, especially in the features, KNN might struggle as it relies on the similarity of instances.\n",
    "  - In cases where the training data represents the population well, KNN can be very effective due to its instance-based nature.\n",
    "- **Problem Specifics**:\n",
    "  - KNN classifiers are well-suited for multi-class problems but can struggle with very imbalanced datasets.\n",
    "  - KNN regressors work well for predicting trends but might not perform well with highly volatile data or in scenarios where the prediction needs to extrapolate beyond the range of the training data.\n",
    "\n",
    "### General Considerations\n",
    "- **Preprocessing**: Both classifiers and regressors benefit from feature scaling and handling missing values.\n",
    "- **Parameter Tuning**: The choice of 'k' and the distance metric significantly affects performance.\n",
    "- **Evaluation**: Always use appropriate cross-validation techniques to assess the model’s performance.\n",
    "\n",
    "In conclusion, the choice between a KNN classifier and a regressor boils down to the type of target variable (categorical vs. continuous) and the specific characteristics of the dataset. Neither is universally better; their effectiveness depends on the problem context and how well the assumptions and requirements of KNN align with the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2ff956ea-9b06-43c8-a143-872928b73511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8. What are the strengths and weaknesses of the KNN algorithm for classification and regression tasks,\n",
    "# and how can these be addressed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54236c5e-7f7c-44f5-832f-f53717ffe1a1",
   "metadata": {},
   "source": [
    "The k-Nearest Neighbors (KNN) algorithm is versatile and can be used for both classification and regression tasks. However, it has its own set of strengths and weaknesses, which are important to consider when choosing it for a particular application.\n",
    "\n",
    "### Strengths\n",
    "\n",
    "1. **Simplicity and Intuitiveness**: KNN is easy to understand and implement. The concept of “the closest points are similar” is straightforward and intuitive.\n",
    "\n",
    "2. **No Model Training Phase**: Since KNN is a lazy learner, there is no explicit training phase, which can be advantageous when working with very large datasets.\n",
    "\n",
    "3. **Flexibility with Distance Functions**: You can choose the distance metric (e.g., Euclidean, Manhattan) that best suits your data.\n",
    "\n",
    "4. **Versatility**: KNN can be used for both classification (predicting a category) and regression (predicting a continuous value), and it can handle multi-class problems.\n",
    "\n",
    "5. **Non-Parametric**: It makes no assumptions about the underlying data distribution, which is useful with real-world data where these distributions are not known.\n",
    "\n",
    "### Weaknesses\n",
    "\n",
    "1. **Curse of Dimensionality**: Its performance degrades with an increasing number of features due to the sparsity of high-dimensional space.\n",
    "\n",
    "2. **Sensitive to Noisy or Irrelevant Features**: Since KNN relies on feature similarity, the presence of irrelevant features can significantly degrade the model's performance.\n",
    "\n",
    "3. **Computational Intensity During Prediction**: As a lazy learner, KNN requires storing the entire dataset and calculating distances for each query, which can be computationally expensive.\n",
    "\n",
    "4. **Memory Requirement**: It requires keeping the entire dataset in memory, which can be a problem for large datasets.\n",
    "\n",
    "5. **Sensitivity to Imbalanced Data**: In classification, KNN can be biased towards the more prevalent class.\n",
    "\n",
    "6. **Sensitivity to Data Scale**: Features need to be scaled for KNN to work correctly, as features on larger scales can unduly influence the distance computations.\n",
    "\n",
    "### Addressing Weaknesses\n",
    "\n",
    "1. **Dimensionality Reduction**: Use techniques like PCA (Principal Component Analysis) to reduce the number of dimensions.\n",
    "\n",
    "2. **Feature Selection**: Employ feature selection techniques to keep only the most relevant features, thereby reducing noise and computation.\n",
    "\n",
    "3. **Weighted KNN**: Modify the algorithm to give more weight to nearer neighbors, which can be particularly effective in regression tasks.\n",
    "\n",
    "4. **Data Preprocessing**: Normalize or standardize data to ensure all features contribute equally to the distance calculations.\n",
    "\n",
    "5. **Handling Imbalanced Data**: Use techniques like SMOTE (Synthetic Minority Over-sampling Technique) for oversampling the minority class in classification problems.\n",
    "\n",
    "6. **Optimizing 'k' Value**: Use cross-validation to find an optimal 'k' value that strikes a balance between bias and variance.\n",
    "\n",
    "7. **Advanced Distance Metrics**: Experiment with different distance metrics that might be more suitable for your specific dataset.\n",
    "\n",
    "8. **Using a KD-Tree or Ball Tree for Large Datasets**: These data structures can significantly speed up nearest neighbor searches on large datasets.\n",
    "\n",
    "By understanding and addressing these strengths and weaknesses, KNN can be effectively utilized for both classification and regression tasks in various scenarios. However, it's always important to consider the specific requirements and constraints of your application before choosing KNN as your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6044168-867e-496d-abef-7c848653b905",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9. What is the difference between Euclidean distance and Manhattan distance in KNN?"
   ]
  },
  {
   "attachments": {
    "0451e2a2-7fea-414c-99dc-7f8f6aad492c.png": {
     "image/png": "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"
    },
    "81045b79-e9d3-4253-8918-826dbcd70319.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "55e24f0a-2ab2-452f-84e4-f77ab9a1bb92",
   "metadata": {},
   "source": [
    "In the k-Nearest Neighbors (KNN) algorithm, distance metrics are used to calculate the similarity between data points. Euclidean distance and Manhattan distance are two common metrics for this purpose. Understanding their differences is crucial for selecting the most appropriate one based on the characteristics of your data.\n",
    "\n",
    "### Euclidean Distance\n",
    "\n",
    "- **Definition**: Euclidean distance is the \"ordinary\" straight-line distance between two points in Euclidean space. In a two-dimensional space, it's the length of the hypotenuse of a right-angled triangle.\n",
    "  \n",
    "- **Formula**: For two points \\(x\\) and \\(y\\) in an \\(n\\)-dimensional space with coordinates \n",
    "\n",
    "![image.png](attachment:81045b79-e9d3-4253-8918-826dbcd70319.png)\n",
    "\n",
    "\n",
    "- **Characteristics**:\n",
    "  - Measures the shortest path between points.\n",
    "  - Is affected more by larger differences in a single dimension due to the squaring of differences.\n",
    "  - Most common and default choice in many applications.\n",
    "\n",
    "### Manhattan Distance\n",
    "\n",
    "- **Definition**: Manhattan distance, also known as Taxicab distance or L1 distance, calculates the distance between two points in a grid-based path (like Manhattan's streets). It is the sum of the absolute differences of their coordinates.\n",
    "\n",
    "- **Formula**: For the same points \\(x\\) and \\(y\\) in an \\(n\\)-dimensional space, the Manhattan distance \\(D\\) is calculated as:\n",
    "\n",
    "  ![image.png](attachment:0451e2a2-7fea-414c-99dc-7f8f6aad492c.png)\n",
    "- **Characteristics**:\n",
    "  - Measures the distance traveling along axes at right angles.\n",
    "  - It can be more robust to outliers than the Euclidean distance.\n",
    "  - Preferred in grid-like path scenarios and when working with high-dimensional data.\n",
    "\n",
    "### Key Differences\n",
    "\n",
    "1. **Path**: Euclidean distance is the straight-line distance, whereas Manhattan distance is the sum of absolute vertical and horizontal distances.\n",
    "\n",
    "2. **Sensitivity to Outliers**: Euclidean distance can be greatly influenced by outliers or large differences in a single dimension due to squaring each difference, while Manhattan distance is less sensitive to this.\n",
    "\n",
    "3. **Computation in High-Dimensional Space**: In high-dimensional spaces, Manhattan distance is often more useful as it reflects the structure of these spaces better than the Euclidean distance.\n",
    "\n",
    "4. **Use Cases**:\n",
    "   - Euclidean distance is used in scenarios where the shortest direct distance is preferred.\n",
    "   - Manhattan distance is used in urban or grid-like structures and is also preferred in high-dimensional data analysis.\n",
    "\n",
    "### Choice in KNN\n",
    "\n",
    "The choice between Euclidean and Manhattan distance in KNN should be based on the dataset's characteristics and the problem's nature. If the dataset contains outliers, Manhattan distance can be more resilient. For spatial data representing physical distances, Euclidean distance is more appropriate. Experimenting with both distances and validating their performance on a specific task is often the best way to decide."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea428d74-9bbc-4ec7-9417-262358040efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10. What is the role of feature scaling in KNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60ee861-8903-4db4-adb5-89c66ade936b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature scaling plays a crucial role in the performance of the k-Nearest Neighbors (KNN) algorithm due to its reliance on distance calculations. Here's a detailed explanation of why feature scaling is important in KNN:\n",
    "\n",
    "### Nature of KNN\n",
    "\n",
    "- KNN calculates the distances between data points to determine the 'nearest neighbors.' These distances significantly influence the classification or regression outcome.\n",
    "\n",
    "### Impact of Feature Scaling\n",
    "\n",
    "1. **Equal Contribution of Features**: Without scaling, features with larger ranges dominate the distance calculations. For example, in a dataset with features like income (ranging in thousands) and age (ranging from 1 to 100), the income feature will disproportionately influence the distance. Scaling ensures that each feature contributes approximately equally to the distance calculation.\n",
    "\n",
    "2. **Improving Algorithm Performance**: When features are on different scales, KNN can perform poorly. This is because the algorithm might end up giving undue importance to some features over others, leading to inaccurate classifications or predictions.\n",
    "\n",
    "3. **Speed of Convergence**: Properly scaled features can also speed up the convergence of the algorithm, especially in scenarios involving gradient descent in distance computation.\n",
    "\n",
    "### Methods of Feature Scaling\n",
    "\n",
    "1. **Normalization (Min-Max Scaling)**: This technique scales the data to fit into a specific range, typically 0 to 1, using the formula:\n",
    "   \n",
    "\n",
    "\n",
    "   This method is useful when you know the approximate minimum and maximum values of your data.\n",
    "\n",
    "2. **Standardization (Z-score Normalization)**: This approach rescales data so it has a mean of 0 and a standard deviation of 1, using the formula:\n",
    "\n",
    "   \\[ X_{\\text{std}} = \\frac{X - \\mu}{\\sigma} \\]\n",
    "\n",
    "   where \\(\\mu\\) is the mean and \\(\\sigma\\) is the standard deviation. Standardization is less affected by outliers and is often preferred when the data does not have a specific range.\n",
    "\n",
    "### Choosing the Right Scaling Method\n",
    "\n",
    "- The choice between normalization and standardization depends on the dataset and the specific problem context. \n",
    "- If the data contains outliers, standardization is often more robust.\n",
    "- If the data has a known range (like pixel intensities in an image, ranging from 0 to 255), normalization might be more appropriate.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "In summary, feature scaling is vital for KNN to ensure that all features contribute equally to the distance calculations. Proper scaling can significantly improve the accuracy and efficiency of a KNN model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
